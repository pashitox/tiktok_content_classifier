{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a709e56",
   "metadata": {},
   "source": [
    "# Proyecto Final - Curso 6: Clasificación de Reclamaciones en TikTok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6fbb5",
   "metadata": {},
   "source": [
    "**Objetivo:** Construir un modelo de bosque aleatorio para predecir si un video publicado en TikTok representa una 'reclamación' o una 'opinión'.\n",
    "\n",
    "**Contexto:** El equipo de datos de TikTok desea automatizar la revisión de informes de usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b9961",
   "metadata": {},
   "source": [
    "## Carga de datos sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "323bf304-575b-4ddf-ba6e-2433c4fffb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\jmgy-\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from nltk) (1.5.0)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jmgy-\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jmgy-\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Installing collected packages: regex, click, nltk\n",
      "Successfully installed click-8.2.1 nltk-3.9.1 regex-2024.11.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f228fc-8345-4913-ae7c-1132ef64696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JMGY-\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8cb9b28-5460-474b-b352-5cef01ca59cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset cargado.\n",
      "\n",
      "🧾 Columnas disponibles: ['#', 'claim_status', 'video_id', 'video_duration_sec', 'video_transcription_text', 'verified_status', 'author_ban_status', 'video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo original\n",
    "df = pd.read_csv(\"tiktok_dataset.csv\")  # asegurate de que esté en el mismo directorio\n",
    "print(\"✅ Dataset cargado.\")\n",
    "print(\"\\n🧾 Columnas disponibles:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d927291c-4ad0-43fd-b0f8-c221b95fdffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Primeras filas del dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>claim_status</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_duration_sec</th>\n",
       "      <th>video_transcription_text</th>\n",
       "      <th>verified_status</th>\n",
       "      <th>author_ban_status</th>\n",
       "      <th>video_view_count</th>\n",
       "      <th>video_like_count</th>\n",
       "      <th>video_share_count</th>\n",
       "      <th>video_download_count</th>\n",
       "      <th>video_comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>claim</td>\n",
       "      <td>7017666017</td>\n",
       "      <td>59</td>\n",
       "      <td>someone shared with me that drone deliveries a...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>under review</td>\n",
       "      <td>343296.0</td>\n",
       "      <td>19425.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>claim</td>\n",
       "      <td>4014381136</td>\n",
       "      <td>32</td>\n",
       "      <td>someone shared with me that there are more mic...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>140877.0</td>\n",
       "      <td>77355.0</td>\n",
       "      <td>19034.0</td>\n",
       "      <td>1161.0</td>\n",
       "      <td>684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>claim</td>\n",
       "      <td>9859838091</td>\n",
       "      <td>31</td>\n",
       "      <td>someone shared with me that american industria...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>902185.0</td>\n",
       "      <td>97690.0</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>claim</td>\n",
       "      <td>1866847991</td>\n",
       "      <td>25</td>\n",
       "      <td>someone shared with me that the metro of st. p...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>437506.0</td>\n",
       "      <td>239954.0</td>\n",
       "      <td>34812.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>claim</td>\n",
       "      <td>7105231098</td>\n",
       "      <td>19</td>\n",
       "      <td>someone shared with me that the number of busi...</td>\n",
       "      <td>not verified</td>\n",
       "      <td>active</td>\n",
       "      <td>56167.0</td>\n",
       "      <td>34987.0</td>\n",
       "      <td>4110.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # claim_status    video_id  video_duration_sec  \\\n",
       "0  1        claim  7017666017                  59   \n",
       "1  2        claim  4014381136                  32   \n",
       "2  3        claim  9859838091                  31   \n",
       "3  4        claim  1866847991                  25   \n",
       "4  5        claim  7105231098                  19   \n",
       "\n",
       "                            video_transcription_text verified_status  \\\n",
       "0  someone shared with me that drone deliveries a...    not verified   \n",
       "1  someone shared with me that there are more mic...    not verified   \n",
       "2  someone shared with me that american industria...    not verified   \n",
       "3  someone shared with me that the metro of st. p...    not verified   \n",
       "4  someone shared with me that the number of busi...    not verified   \n",
       "\n",
       "  author_ban_status  video_view_count  video_like_count  video_share_count  \\\n",
       "0      under review          343296.0           19425.0              241.0   \n",
       "1            active          140877.0           77355.0            19034.0   \n",
       "2            active          902185.0           97690.0             2858.0   \n",
       "3            active          437506.0          239954.0            34812.0   \n",
       "4            active           56167.0           34987.0             4110.0   \n",
       "\n",
       "   video_download_count  video_comment_count  \n",
       "0                   1.0                  0.0  \n",
       "1                1161.0                684.0  \n",
       "2                 833.0                329.0  \n",
       "3                1234.0                584.0  \n",
       "4                 547.0                152.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n🔎 Primeras filas del dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c920ee8-6350-4c6d-8757-e590be26360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔢 El dataset tiene 19382 filas y 12 columnas.\n",
      "\n",
      "📋 Tipos de datos:\n",
      "#                             int64\n",
      "claim_status                 object\n",
      "video_id                      int64\n",
      "video_duration_sec            int64\n",
      "video_transcription_text     object\n",
      "verified_status              object\n",
      "author_ban_status            object\n",
      "video_view_count            float64\n",
      "video_like_count            float64\n",
      "video_share_count           float64\n",
      "video_download_count        float64\n",
      "video_comment_count         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n🔢 El dataset tiene {df.shape[0]} filas y {df.shape[1]} columnas.\")\n",
    "print(\"\\n📋 Tipos de datos:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8c8b29-1c9a-4681-909f-5e0d51a82e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧼 Valores nulos por columna:\n",
      "#                             0\n",
      "claim_status                298\n",
      "video_id                      0\n",
      "video_duration_sec            0\n",
      "video_transcription_text    298\n",
      "verified_status               0\n",
      "author_ban_status             0\n",
      "video_view_count            298\n",
      "video_like_count            298\n",
      "video_share_count           298\n",
      "video_download_count        298\n",
      "video_comment_count         298\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🧼 Valores nulos por columna:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567b2760-3418-4ee4-b32b-72d61a0e1460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Algunos textos:\n",
      "13967    my friends' impression is that the longest pos...\n",
      "8051     i read a story claiming that mice typically on...\n",
      "15730    my family's hypothesis is that it would take 2...\n",
      "7923     someone discovered a report claiming that the ...\n",
      "16528    my colleagues' sentiment is that the average c...\n",
      "Name: video_transcription_text, dtype: object\n",
      "\n",
      "📉 Cantidad de textos vacíos o solo espacios:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if 'video_transcription_text' in df.columns:\n",
    "    print(\"\\n📝 Algunos textos:\")\n",
    "    print(df['video_transcription_text'].dropna().sample(min(5, len(df))))\n",
    "    print(\"\\n📉 Cantidad de textos vacíos o solo espacios:\")\n",
    "    print((df['video_transcription_text'].str.strip() == '').sum())\n",
    "else:\n",
    "    print(\"\\n⚠️ La columna 'video_transcription_text' no está en el dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd1a1543-8dcf-463e-a74e-7295ab6335e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 🧼 2. Eliminar filas con NaN importantes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m---> 16\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclaim_status\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclaim_status\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopinión\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreclamación\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 🔐 3. Variables categóricas codificadas\u001b[39;00m\n\u001b[0;32m     19\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverified_status\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_ban_status\u001b[39m\u001b[38;5;124m'\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[0;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m\\\\?\\C:\\Users\\JMGY-\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "# 📦 Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ✅ 1. Cargar y limpiar\n",
    "df = pd.read_csv(\"tiktok_dataset.csv\")\n",
    "\n",
    "# 🧼 2. Eliminar filas con NaN importantes\n",
    "df = df.dropna()\n",
    "df['claim_status'] = df['claim_status'].map({'opinión': 0, 'reclamación': 1})\n",
    "df = df.dropna(subset=['claim_status'])  # eliminar solo las filas no mapeadas\n",
    "df['claim_status'] = df['claim_status'].astype(int)\n",
    "\n",
    "# 🔐 3. Variables categóricas codificadas\n",
    "df = pd.get_dummies(df, columns=['verified_status', 'author_ban_status'], drop_first=True)\n",
    "\n",
    "# 🧠 4. Procesamiento texto TF-IDF\n",
    "df['video_transcription_text'] = df['video_transcription_text'].fillna('').astype(str)\n",
    "tfidf = TfidfVectorizer(max_features=50, token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X_text = pd.DataFrame(tfidf.fit_transform(df['video_transcription_text']).toarray())\n",
    "df = df.drop(columns='video_transcription_text')\n",
    "\n",
    "# 🧩 5. Separar X e y\n",
    "X = pd.concat([df.drop(columns='claim_status').reset_index(drop=True), X_text], axis=1)\n",
    "X.columns = X.columns.astype(str)\n",
    "y = df['claim_status']\n",
    "\n",
    "# 🔀 6. División\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 🌳 7. Entrenamiento\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 📈 8. Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 📋 9. Evaluación\n",
    "print(\"\\n📊 Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"🎯 AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "# 📉 10. Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC - Random Forest')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('Falsos Positivos')\n",
    "plt.ylabel('Verdaderos Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 🧱 11. Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c58ce6c-db8b-4277-905d-3c3c9a9e119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Librerías importadas.\n",
      "✅ Dataset cargado.\n",
      "['#', 'claim_status', 'video_id', 'video_duration_sec', 'video_transcription_text', 'verified_status', 'author_ban_status', 'video_view_count', 'video_like_count', 'video_share_count', 'video_download_count', 'video_comment_count']\n",
      "🔁 Variable objetivo codificada y limpiada.\n",
      "🔁 Variables categóricas codificadas.\n",
      "\n",
      "📝 Ejemplo de textos:\n",
      "Series([], Name: video_transcription_text, dtype: object)\n",
      "\n",
      "🧮 Textos útiles encontrados: 0 de 0\n",
      "⚠️ No se encontraron textos útiles. Omite TF-IDF.\n",
      "\n",
      "⛔ Dataset final vacío. No se puede entrenar el modelo.\n"
     ]
    }
   ],
   "source": [
    "# 📦 1. Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"✅ Librerías importadas.\")\n",
    "\n",
    "# 📥 2. Cargar datos\n",
    "df = pd.read_csv(\"tiktok_dataset.csv\")\n",
    "print(\"✅ Dataset cargado.\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# 🧹 3. Codificar variable objetivo\n",
    "df['claim_status'] = df['claim_status'].map({'opinión': 0, 'reclamación': 1})\n",
    "df = df.dropna(subset=['claim_status'])\n",
    "df['claim_status'] = df['claim_status'].astype(int)\n",
    "print(\"🔁 Variable objetivo codificada y limpiada.\")\n",
    "\n",
    "# 🔐 4. Codificar variables categóricas\n",
    "categoricas = ['verified_status', 'author_ban_status']\n",
    "df = pd.get_dummies(df, columns=categoricas, drop_first=True)\n",
    "print(\"🔁 Variables categóricas codificadas.\")\n",
    "\n",
    "# 🧠 5. Procesar texto solo si la columna existe\n",
    "if 'video_transcription_text' in df.columns:\n",
    "    print(\"\\n📝 Ejemplo de textos:\")\n",
    "    df['video_transcription_text'] = df['video_transcription_text'].fillna('').astype(str)\n",
    "    print(df['video_transcription_text'].sample(min(5, len(df))))\n",
    "\n",
    "    df['texto_util'] = df['video_transcription_text'].str.strip().str.split().str.len()\n",
    "    df_text = df[df['texto_util'] > 2].copy()\n",
    "\n",
    "    print(f\"\\n🧮 Textos útiles encontrados: {len(df_text)} de {len(df)}\")\n",
    "\n",
    "    if len(df_text) > 0:\n",
    "        tfidf = TfidfVectorizer(max_features=50, token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "        X_text = pd.DataFrame(tfidf.fit_transform(df_text['video_transcription_text']).toarray())\n",
    "        df_text = df_text.drop(columns=['video_transcription_text', 'texto_util'])\n",
    "        df_model = pd.concat([df_text.reset_index(drop=True), X_text], axis=1)\n",
    "        print(\"✅ TF-IDF aplicado correctamente.\")\n",
    "    else:\n",
    "        print(\"⚠️ No se encontraron textos útiles. Omite TF-IDF.\")\n",
    "        df = df.drop(columns=['video_transcription_text', 'texto_util'], errors='ignore')\n",
    "        df_model = df.copy()\n",
    "else:\n",
    "    print(\"⚠️ Columna 'video_transcription_text' no está en el dataset. Continuamos sin texto.\")\n",
    "    df_model = df.copy()\n",
    "\n",
    "# 🧩 6. Armar X e y\n",
    "if df_model.empty:\n",
    "    print(\"\\n⛔ Dataset final vacío. No se puede entrenar el modelo.\")\n",
    "else:\n",
    "    X = df_model.drop(columns='claim_status')\n",
    "    y = df_model['claim_status']\n",
    "    print(f\"\\n✅ Dataset final con {len(X)} muestras.\")\n",
    "\n",
    "    # 🔀 7. División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # 📊 8. Evaluación\n",
    "    print(\"\\n📋 Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"🎯 AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "    # 📈 9. Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel('Falsos Positivos')\n",
    "    plt.ylabel('Verdaderos Positivos')\n",
    "    plt.title('Curva ROC')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 🧱 10. Matriz de Confusión\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Real')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f253bc83-bdaf-473a-92a1-ecd77bceff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
